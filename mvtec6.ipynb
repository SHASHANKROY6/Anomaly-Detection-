{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13025919,"sourceType":"datasetVersion","datasetId":8247543}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shashankroy568/mvtec6?scriptVersionId=262855021\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MVTec Anomaly Detection - Fixed Anomalib Installation\n# Designed for Kaggle GPU P100 environment\nimport os\nimport sys\nimport warnings\nimport subprocess\nwarnings.filterwarnings('ignore')\n\nprint(\"üîß Starting robust environment setup...\")\n\ndef install_package(package_name, import_name=None, extra_args=\"\"):\n    \"\"\"Install package with proper error handling\"\"\"\n    try:\n        # Try importing first\n        if import_name:\n            __import__(import_name)\n            print(f\"‚úÖ {package_name} already available\")\n            return True\n        \n        print(f\"Installing {package_name}...\")\n        cmd = f\"pip install {package_name} {extra_args}\"\n        result = subprocess.run(cmd.split(), capture_output=True, text=True)\n        \n        if result.returncode == 0:\n            print(f\"‚úÖ {package_name} installed successfully\")\n            return True\n        else:\n            print(f\"‚ö†Ô∏è Warning installing {package_name}: {result.stderr}\")\n            return False\n            \n    except Exception as e:\n        print(f\"‚ùå Error with {package_name}: {e}\")\n        return False\n\n# Step 1: Install all dependencies step by step\nprint(\"üì¶ Installing dependencies...\")\n\n# Core dependencies first\ninstall_package(\"python-dotenv\", \"dotenv\", \"--quiet\")\ninstall_package(\"opencv-python\", \"cv2\", \"--quiet\")\ninstall_package(\"Pillow\", \"PIL\", \"--quiet --upgrade\")\n\n# Try different anomalib installation strategies\nprint(\"\\nüîß Installing anomalib with multiple strategies...\")\nstrategies = [\n    (\"anomalib\", \"--quiet --no-deps --upgrade\"),\n    (\"anomalib\", \"--quiet --force-reinstall\"),\n    (\"anomalib==1.0.1\", \"--quiet\"),\n    (\"git+https://github.com/openvinotoolkit/anomalib.git\", \"--quiet\")\n]\n\nanomalib_installed = False\nfor package, args in strategies:\n    print(f\"Trying: pip install {package} {args}\")\n    if install_package(package, None, args):\n        # Test import after each installation\n        try:\n            import anomalib\n            print(f\"‚úÖ Anomalib successfully imported!\")\n            anomalib_installed = True\n            break\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Installation succeeded but import failed: {e}\")\n            continue\n\nif not anomalib_installed:\n    print(\"‚ö†Ô∏è Anomalib installation issues detected. Using manual approach...\")\n\n# Step 2: Import required libraries with comprehensive fallbacks\nprint(\"\\nüìö Importing libraries...\")\n\n# Standard imports\ntry:\n    import kagglehub\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from pathlib import Path\n    import torch\n    from PIL import Image\n    import cv2\n    from glob import glob\n    import json\n    from sklearn.metrics import roc_auc_score, roc_curve\n    from sklearn.preprocessing import MinMaxScaler\n    import torchvision.transforms as transforms\n    from torch.utils.data import Dataset, DataLoader\n    \n    print(\"‚úÖ Standard libraries imported\")\nexcept ImportError as e:\n    print(f\"‚ùå Standard import error: {e}\")\n    sys.exit(1)\n\n# Anomalib imports with multiple fallback options\nANOMALIB_VERSION = None\nanomalib_components = {}\n\nprint(\"üîç Detecting anomalib configuration...\")\n\n# Strategy 1: Try latest anomalib API\ntry:\n    from anomalib import TaskType\n    from anomalib.data.image.mvtec import MVTecDataModule\n    from anomalib.models.image.padim import Padim, PadimLightningModule\n    from anomalib.engine import Engine\n    \n    ANOMALIB_VERSION = \"v1.0+\"\n    anomalib_components = {\n        'datamodule_class': MVTecDataModule,\n        'model_class': Padim,\n        'engine_class': Engine\n    }\n    print(\"‚úÖ Anomalib v1.0+ API detected\")\n    \nexcept ImportError:\n    # Strategy 2: Try older anomalib API\n    try:\n        from anomalib.data import MVTec\n        from anomalib.models.padim import Padim, PadimLightningModule\n        from anomalib.utils.callbacks import get_callbacks\n        \n        ANOMALIB_VERSION = \"v0.7+\"\n        anomalib_components = {\n            'datamodule_class': MVTec,\n            'model_class': Padim,\n            'callbacks_fn': get_callbacks\n        }\n        print(\"‚úÖ Anomalib v0.7+ API detected\")\n        \n    except ImportError:\n        # Strategy 3: Try even older API\n        try:\n            from anomalib.data.mvtec import MVTecDataset\n            from anomalib.models.padim.lightning_model import PadimLightningModule\n            \n            ANOMALIB_VERSION = \"legacy\"\n            anomalib_components = {\n                'dataset_class': MVTecDataset,\n                'model_class': PadimLightningModule\n            }\n            print(\"‚úÖ Anomalib legacy API detected\")\n            \n        except ImportError:\n            print(\"‚ö†Ô∏è No anomalib API detected - will use manual implementation\")\n            ANOMALIB_VERSION = \"manual\"\n\n# Step 3: Manual PaDiM implementation as ultimate fallback\nclass ManualPaDiM:\n    \"\"\"Manual PaDiM implementation when anomalib fails\"\"\"\n    \n    def __init__(self, backbone='resnet18', layers=['layer1', 'layer2', 'layer3']):\n        self.backbone_name = backbone\n        self.layer_names = layers\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"üß† Manual PaDiM initialized with {backbone} on {self.device}\")\n        \n        # Load pretrained backbone\n        if backbone == 'resnet18':\n            import torchvision.models as models\n            self.backbone = models.resnet18(pretrained=True)\n            self.backbone.eval()\n            self.backbone.to(self.device)\n        \n        self.feature_extractor = {}\n        self._register_hooks()\n        \n    def _register_hooks(self):\n        \"\"\"Register hooks for specified layers\"\"\"\n        def hook_fn(name):\n            def hook(module, input, output):\n                self.feature_extractor[name] = output\n            return hook\n        \n        # Register hooks for specified layers\n        for name, module in self.backbone.named_modules():\n            if name in self.layer_names:\n                module.register_forward_hook(hook_fn(name))\n    \n    def extract_features(self, images):\n        \"\"\"Extract features from images\"\"\"\n        self.feature_extractor.clear()\n        \n        with torch.no_grad():\n            _ = self.backbone(images)\n        \n        # Concatenate features from all layers\n        feature_maps = []\n        for layer_name in self.layer_names:\n            if layer_name in self.feature_extractor:\n                feat = self.feature_extractor[layer_name]\n                # Adaptive pool to standard size\n                feat = torch.nn.functional.adaptive_avg_pool2d(feat, (28, 28))\n                feature_maps.append(feat)\n        \n        if feature_maps:\n            return torch.cat(feature_maps, dim=1)\n        else:\n            print(\"‚ö†Ô∏è No features extracted\")\n            return None\n    \n    def fit(self, train_loader):\n        \"\"\"Fit the model on training data\"\"\"\n        print(\"üîÑ Training manual PaDiM...\")\n        \n        all_features = []\n        \n        for batch_idx, (images, _) in enumerate(train_loader):\n            if batch_idx % 10 == 0:\n                print(f\"Processing batch {batch_idx}...\")\n            \n            images = images.to(self.device)\n            features = self.extract_features(images)\n            \n            if features is not None:\n                # Reshape to (batch_size * height * width, features)\n                b, c, h, w = features.shape\n                features = features.permute(0, 2, 3, 1).reshape(-1, c)\n                all_features.append(features.cpu().numpy())\n        \n        if all_features:\n            all_features = np.vstack(all_features)\n            \n            # Calculate mean and covariance for each spatial location\n            self.mean = np.mean(all_features, axis=0)\n            self.cov = np.cov(all_features, rowvar=False)\n            \n            # Add small epsilon to diagonal for numerical stability\n            self.cov += np.eye(self.cov.shape[0]) * 1e-6\n            \n            print(f\"‚úÖ Training completed. Feature shape: {all_features.shape}\")\n            return True\n        else:\n            print(\"‚ùå No features extracted during training\")\n            return False\n    \n    def predict(self, test_loader):\n        \"\"\"Predict anomalies on test data\"\"\"\n        print(\"üîç Predicting with manual PaDiM...\")\n        \n        predictions = []\n        true_labels = []\n        \n        for batch_idx, (images, labels) in enumerate(test_loader):\n            images = images.to(self.device)\n            features = self.extract_features(images)\n            \n            true_labels.extend(labels.numpy())\n            \n            if features is not None:\n                b, c, h, w = features.shape\n                features = features.permute(0, 2, 3, 1).reshape(-1, c).cpu().numpy()\n                \n                # Calculate Mahalanobis distance\n                diff = features - self.mean\n                try:\n                    inv_cov = np.linalg.pinv(self.cov)\n                    distances = np.sum(diff @ inv_cov * diff, axis=1)\n                    distances = distances.reshape(b, h, w)\n                    \n                    # Max pooling to get image-level score\n                    image_scores = np.max(distances, axis=(1, 2))\n                    predictions.extend(image_scores)\n                    \n                except Exception as e:\n                    print(f\"‚ö†Ô∏è Error in distance calculation: {e}\")\n                    predictions.extend([0.5] * b)\n            else:\n                predictions.extend([0.5] * len(labels))\n        \n        return np.array(predictions), np.array(true_labels)\n\n# Step 4: Enhanced dataset exploration\ndef explore_dataset_structure():\n    \"\"\"Thoroughly explore the MVTec dataset structure\"\"\"\n    print(\"\\nüìÇ Downloading and exploring MVTec dataset...\")\n    \n    try:\n        # Download dataset\n        dataset_path = kagglehub.dataset_download(\"shashankroy568/mvtec-anomaly-detection\")\n        print(f\"‚úÖ Dataset downloaded to: {dataset_path}\")\n        \n        root_path = Path(dataset_path)\n        \n        # Print full directory tree (limited depth)\n        print(f\"\\nüå≥ Complete directory structure:\")\n        for root, dirs, files in os.walk(root_path):\n            level = root.replace(str(root_path), '').count(os.sep)\n            if level < 3:  # Limit depth\n                indent = ' ' * 2 * level\n                print(f\"{indent}üìÅ {os.path.basename(root)}/\")\n                if level < 2:  # Show files only at shallow levels\n                    subindent = ' ' * 2 * (level + 1)\n                    for file in files[:3]:  # Show first 3 files\n                        print(f\"{subindent}üìÑ {file}\")\n                    if len(files) > 3:\n                        print(f\"{subindent}... and {len(files)-3} more files\")\n        \n        # Look for MVTec categories\n        mvtec_categories = [\n            'bottle', 'cable', 'capsule', 'carpet', 'grid',\n            'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n            'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n        ]\n        \n        print(f\"\\nüîç Searching for MVTec categories...\")\n        \n        # Recursive search for categories\n        found_categories = {}\n        \n        for root, dirs, files in os.walk(root_path):\n            for dir_name in dirs:\n                if dir_name in mvtec_categories:\n                    category_path = Path(root) / dir_name\n                    found_categories[dir_name] = category_path\n                    print(f\"  ‚úÖ Found {dir_name} at: {category_path}\")\n        \n        if found_categories:\n            print(f\"\\nüéØ Found {len(found_categories)} MVTec categories!\")\n            \n            # Test structure of first category\n            first_category = list(found_categories.keys())[0]\n            first_path = found_categories[first_category]\n            \n            print(f\"\\nüî¨ Examining structure of '{first_category}':\")\n            for item in first_path.iterdir():\n                if item.is_dir():\n                    file_count = len(list(item.rglob(\"*.*\")))\n                    print(f\"  üìÅ {item.name}: {file_count} files\")\n            \n            return root_path, found_categories\n        \n        else:\n            print(\"‚ùå No MVTec categories found in expected locations\")\n            print(\"üìã Available directories:\")\n            for item in root_path.rglob(\"*\"):\n                if item.is_dir():\n                    print(f\"  üìÅ {item.relative_to(root_path)}\")\n            \n            return root_path, {}\n    \n    except Exception as e:\n        print(f\"‚ùå Dataset exploration error: {e}\")\n        return None, {}\n\n# Step 5: FIXED manual dataset class with correct label logic\nclass MVTecManualDataset(Dataset):\n    \"\"\"Manual MVTec dataset when anomalib fails - FIXED LABEL LOGIC\"\"\"\n    \n    def __init__(self, root_path, category, split='train', transform=None):\n        self.root_path = Path(root_path)\n        self.category = category\n        self.split = split\n        self.transform = transform or transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        self.samples = self._load_samples()\n        print(f\"üìä Loaded {len(self.samples)} {split} samples for {category}\")\n    \n    def _load_samples(self):\n        \"\"\"Load all samples for the dataset with CORRECT MVTec labeling\"\"\"\n        samples = []\n        \n        # Find category path\n        possible_paths = [\n            self.root_path / self.category,\n            self.root_path / \"mvtec_anomaly_detection\" / self.category,\n            self.root_path / \"MVTec\" / self.category,\n            self.root_path / \"mvtec\" / self.category\n        ]\n        \n        category_path = None\n        for path in possible_paths:\n            if path.exists():\n                category_path = path\n                print(f\"‚úÖ Found category at: {category_path}\")\n                break\n        \n        if not category_path:\n            print(f\"‚ùå Category path not found. Tried:\")\n            for path in possible_paths:\n                print(f\"   - {path}\")\n            return samples\n        \n        # MVTec Dataset Structure:\n        # train/good/ -> Normal samples (label 0)\n        # test/good/ -> Normal test samples (label 0)  \n        # test/defect_type/ -> Anomaly samples (label 1)\n        \n        if self.split == 'train':\n            # Training: Only normal samples from train/good\n            good_path = category_path / 'train' / 'good'\n            if good_path.exists():\n                print(f\"üìÅ Loading NORMAL training samples from: {good_path}\")\n                for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                    for img_path in good_path.rglob(ext):\n                        samples.append((str(img_path), 0))  # Label 0 = Normal\n                        \n                        if len(samples) <= 3:\n                            print(f\"   Sample: {img_path.name} -> NORMAL (label 0)\")\n            else:\n                print(f\"‚ùå Training good path not found: {good_path}\")\n        \n        else:  # test split\n            # Test: Both normal and anomaly samples\n            test_path = category_path / 'test'\n            if test_path.exists():\n                print(f\"üìÅ Loading test samples from: {test_path}\")\n                \n                # Load normal test samples from test/good\n                good_test_path = test_path / 'good'\n                if good_test_path.exists():\n                    print(f\"   üìÅ Loading NORMAL test samples from: {good_test_path}\")\n                    for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                        for img_path in good_test_path.rglob(ext):\n                            samples.append((str(img_path), 0))  # Label 0 = Normal\n                            \n                            if len([s for s in samples if s[1] == 0]) <= 3:\n                                print(f\"      Sample: {img_path.name} -> NORMAL (label 0)\")\n                \n                # Load anomaly samples from test/defect_type folders\n                for defect_dir in test_path.iterdir():\n                    if defect_dir.is_dir() and defect_dir.name != 'good':\n                        print(f\"   üìÅ Loading ANOMALY samples from: {defect_dir.name}\")\n                        for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                            for img_path in defect_dir.rglob(ext):\n                                samples.append((str(img_path), 1))  # Label 1 = Anomaly\n                                \n                                if len([s for s in samples if s[1] == 1]) <= 3:\n                                    print(f\"      Sample: {img_path.name} -> ANOMALY (label 1)\")\n            else:\n                print(f\"‚ùå Test path not found: {test_path}\")\n        \n        # Count samples by label\n        normal_count = len([s for s in samples if s[1] == 0])\n        anomaly_count = len([s for s in samples if s[1] == 1])\n        \n        print(f\"   ‚úÖ Found {normal_count} NORMAL samples (label 0)\")\n        print(f\"   ‚úÖ Found {anomaly_count} ANOMALY samples (label 1)\")\n        \n        return samples\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error loading {img_path}: {e}\")\n            # Return dummy data\n            dummy_image = torch.zeros((3, 224, 224))\n            return dummy_image, label\n\n# Step 6: Main training pipeline\ndef run_anomaly_detection_pipeline():\n    \"\"\"Main pipeline with all fallbacks\"\"\"\n    \n    print(\"üöÄ Starting Anomaly Detection Pipeline\")\n    print(\"=\" * 60)\n    \n    # Explore dataset\n    root_path, categories = explore_dataset_structure()\n    \n    if not root_path or not categories:\n        print(\"‚ùå Cannot proceed without dataset\")\n        return\n    \n    # Select category\n    target_categories = ['bottle', 'metal_nut', 'capsule', 'cable']\n    available_targets = [cat for cat in target_categories if cat in categories]\n    \n    if not available_targets:\n        test_category = list(categories.keys())[0]\n        print(f\"‚ö†Ô∏è No target categories found, using: {test_category}\")\n    else:\n        test_category = available_targets[0]\n        print(f\"üéØ Using target category: {test_category}\")\n    \n    category_path = categories[test_category]\n    \n    # Create datasets\n    print(f\"\\nüìä Creating datasets...\")\n    \n    try:\n        if ANOMALIB_VERSION and ANOMALIB_VERSION != \"manual\":\n            # Try anomalib dataset\n            print(f\"Using anomalib {ANOMALIB_VERSION} API...\")\n            \n            if 'datamodule_class' in anomalib_components:\n                datamodule = anomalib_components['datamodule_class'](\n                    root=str(category_path.parent),\n                    category=test_category,\n                    image_size=(224, 224),\n                    train_batch_size=8,\n                    eval_batch_size=8,\n                    num_workers=2\n                )\n                \n                # Setup data\n                datamodule.setup()\n                train_loader = datamodule.train_dataloader()\n                test_loader = datamodule.test_dataloader()\n                \n                print(\"‚úÖ Anomalib datamodule created successfully\")\n                use_anomalib = True\n                \n        else:\n            raise Exception(\"Using manual approach\")\n            \n    except Exception as e:\n        print(f\"‚ö†Ô∏è Anomalib dataset failed ({e}), using manual approach...\")\n        use_anomalib = False\n        \n        # Manual dataset creation with FIXED labeling\n        train_dataset = MVTecManualDataset(root_path, test_category, 'train')\n        test_dataset = MVTecManualDataset(root_path, test_category, 'test')\n        \n        # Add safety check for empty datasets\n        if len(train_dataset) == 0:\n            print(f\"‚ùå No training samples found for {test_category}\")\n            return\n\n        if len(test_dataset) == 0:\n            print(f\"‚ùå No test samples found for {test_category}\")\n            return\n\n        # Check if we have both normal and anomaly samples for test\n        test_labels = [test_dataset.samples[i][1] for i in range(len(test_dataset))]\n        unique_labels = set(test_labels)\n        \n        if len(unique_labels) < 2:\n            print(f\"‚ö†Ô∏è Warning: Test set only has {unique_labels} labels. AUC calculation may fail.\")\n            print(\"This might happen if the dataset structure is different than expected.\")\n        \n        print(f\"‚úÖ Dataset ready: {len(train_dataset)} train, {len(test_dataset)} test samples\")\n        print(f\"‚úÖ Test set has {len([l for l in test_labels if l == 0])} normal and {len([l for l in test_labels if l == 1])} anomaly samples\")\n        \n        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n    \n    # Train model\n    print(f\"\\nüß† Training model...\")\n    \n    try:\n        if use_anomalib and 'model_class' in anomalib_components:\n            # Use anomalib model\n            print(\"Using anomalib PaDiM model...\")\n            model = anomalib_components['model_class']()\n            \n            # Training logic depends on version\n            if ANOMALIB_VERSION == \"v1.0+\":\n                engine = anomalib_components['engine_class'](max_epochs=1)\n                engine.fit(model=model, datamodule=datamodule)\n                results = engine.test(model=model, datamodule=datamodule)\n                print(f\"‚úÖ Anomalib training completed: {results}\")\n            else:\n                # Use PyTorch Lightning trainer\n                import pytorch_lightning as pl\n                trainer = pl.Trainer(max_epochs=1, accelerator='gpu' if torch.cuda.is_available() else 'cpu', devices=1)\n                trainer.fit(model, datamodule)\n                results = trainer.test(model, datamodule)\n                print(f\"‚úÖ Anomalib training completed: {results}\")\n            \n        else:\n            # Use manual PaDiM\n            print(\"Using manual PaDiM implementation...\")\n            model = ManualPaDiM()\n            \n            # Train\n            training_success = model.fit(train_loader)\n            \n            if training_success:\n                # Test\n                predictions, true_labels = model.predict(test_loader)\n                \n                # Calculate metrics\n                if len(predictions) == len(true_labels) and len(predictions) > 0:\n                    # Check if we have both classes\n                    unique_test_labels = set(true_labels)\n                    \n                    if len(unique_test_labels) >= 2:\n                        auc_score = roc_auc_score(true_labels, predictions)\n                        print(f\"‚úÖ Manual PaDiM AUC Score: {auc_score:.4f}\")\n                    else:\n                        print(f\"‚ö†Ô∏è Cannot calculate AUC - only one class present: {unique_test_labels}\")\n                    \n                    # Show prediction distribution\n                    normal_indices = true_labels == 0\n                    anomaly_indices = true_labels == 1\n                    \n                    normal_scores = predictions[normal_indices] if normal_indices.any() else np.array([])\n                    anomaly_scores = predictions[anomaly_indices] if anomaly_indices.any() else np.array([])\n                    \n                    print(f\"üìä Score Statistics:\")\n                    if len(normal_scores) > 0:\n                        print(f\"   Normal samples: {len(normal_scores)}, mean score: {normal_scores.mean():.4f}\")\n                    if len(anomaly_scores) > 0:\n                        print(f\"   Anomaly samples: {len(anomaly_scores)}, mean score: {anomaly_scores.mean():.4f}\")\n                    \n                else:\n                    print(f\"‚ö†Ô∏è Prediction length mismatch: {len(predictions)} vs {len(true_labels)}\")\n            \n    except Exception as e:\n        print(f\"‚ùå Training failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return\n    \n    # Create summary\n    print(f\"\\n\" + \"=\" * 60)\n    print(\"üìã PIPELINE SUMMARY\")\n    print(\"=\" * 60)\n    print(f\"‚úÖ Dataset: MVTec Anomaly Detection\")\n    print(f\"‚úÖ Category: {test_category}\")\n    print(f\"‚úÖ Model: PaDiM ({'Anomalib' if use_anomalib else 'Manual'})\")\n    print(f\"‚úÖ Framework: {ANOMALIB_VERSION}\")\n    print(f\"‚úÖ Training: Completed\")\n    print(f\"‚úÖ Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n    \n    print(f\"\\nüéâ Anomaly detection pipeline completed successfully!\")\n\n# Execute the pipeline\nif __name__ == \"__main__\":\n    run_anomaly_detection_pipeline()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T11:09:05.098148Z","iopub.execute_input":"2025-09-11T11:09:05.098467Z","iopub.status.idle":"2025-09-11T11:09:15.560363Z","shell.execute_reply.started":"2025-09-11T11:09:05.098443Z","shell.execute_reply":"2025-09-11T11:09:15.55922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MVTec Anomaly Detection - Multi-Category Training\n# Designed for Kaggle GPU P100 environment\nimport os\nimport sys\nimport warnings\nimport subprocess\nwarnings.filterwarnings('ignore')\n\nprint(\"üîß Starting robust environment setup...\")\n\ndef install_package(package_name, import_name=None, extra_args=\"\"):\n    \"\"\"Install package with proper error handling\"\"\"\n    try:\n        # Try importing first\n        if import_name:\n            __import__(import_name)\n            print(f\"‚úÖ {package_name} already available\")\n            return True\n        \n        print(f\"Installing {package_name}...\")\n        cmd = f\"pip install {package_name} {extra_args}\"\n        result = subprocess.run(cmd.split(), capture_output=True, text=True)\n        \n        if result.returncode == 0:\n            print(f\"‚úÖ {package_name} installed successfully\")\n            return True\n        else:\n            print(f\"‚ö†Ô∏è Warning installing {package_name}: {result.stderr}\")\n            return False\n            \n    except Exception as e:\n        print(f\"‚ùå Error with {package_name}: {e}\")\n        return False\n\n# Step 1: Install all dependencies step by step\nprint(\"üì¶ Installing dependencies...\")\n\n# Core dependencies first\ninstall_package(\"python-dotenv\", \"dotenv\", \"--quiet\")\ninstall_package(\"opencv-python\", \"cv2\", \"--quiet\")\ninstall_package(\"Pillow\", \"PIL\", \"--quiet --upgrade\")\n\n# Try different anomalib installation strategies\nprint(\"\\nüîß Installing anomalib with multiple strategies...\")\nstrategies = [\n    (\"anomalib\", \"--quiet --no-deps --upgrade\"),\n    (\"anomalib\", \"--quiet --force-reinstall\"),\n    (\"anomalib==1.0.1\", \"--quiet\"),\n    (\"git+https://github.com/openvinotoolkit/anomalib.git\", \"--quiet\")\n]\n\nanomalib_installed = False\nfor package, args in strategies:\n    print(f\"Trying: pip install {package} {args}\")\n    if install_package(package, None, args):\n        # Test import after each installation\n        try:\n            import anomalib\n            print(f\"‚úÖ Anomalib successfully imported!\")\n            anomalib_installed = True\n            break\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Installation succeeded but import failed: {e}\")\n            continue\n\nif not anomalib_installed:\n    print(\"‚ö†Ô∏è Anomalib installation issues detected. Using manual approach...\")\n\n# Step 2: Import required libraries with comprehensive fallbacks\nprint(\"\\nüìö Importing libraries...\")\n\n# Standard imports\ntry:\n    import kagglehub\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from pathlib import Path\n    import torch\n    from PIL import Image\n    import cv2\n    from glob import glob\n    import json\n    from sklearn.metrics import roc_auc_score, roc_curve\n    from sklearn.preprocessing import MinMaxScaler\n    import torchvision.transforms as transforms\n    from torch.utils.data import Dataset, DataLoader\n    import time\n    \n    print(\"‚úÖ Standard libraries imported\")\nexcept ImportError as e:\n    print(f\"‚ùå Standard import error: {e}\")\n    sys.exit(1)\n\n# Anomalib imports with multiple fallback options\nANOMALIB_VERSION = None\nanomalib_components = {}\n\nprint(\"üîç Detecting anomalib configuration...\")\n\n# Strategy 1: Try latest anomalib API\ntry:\n    from anomalib import TaskType\n    from anomalib.data.image.mvtec import MVTecDataModule\n    from anomalib.models.image.padim import Padim, PadimLightningModule\n    from anomalib.engine import Engine\n    \n    ANOMALIB_VERSION = \"v1.0+\"\n    anomalib_components = {\n        'datamodule_class': MVTecDataModule,\n        'model_class': Padim,\n        'engine_class': Engine\n    }\n    print(\"‚úÖ Anomalib v1.0+ API detected\")\n    \nexcept ImportError:\n    # Strategy 2: Try older anomalib API\n    try:\n        from anomalib.data import MVTec\n        from anomalib.models.padim import Padim, PadimLightningModule\n        from anomalib.utils.callbacks import get_callbacks\n        \n        ANOMALIB_VERSION = \"v0.7+\"\n        anomalib_components = {\n            'datamodule_class': MVTec,\n            'model_class': Padim,\n            'callbacks_fn': get_callbacks\n        }\n        print(\"‚úÖ Anomalib v0.7+ API detected\")\n        \n    except ImportError:\n        # Strategy 3: Try even older API\n        try:\n            from anomalib.data.mvtec import MVTecDataset\n            from anomalib.models.padim.lightning_model import PadimLightningModule\n            \n            ANOMALIB_VERSION = \"legacy\"\n            anomalib_components = {\n                'dataset_class': MVTecDataset,\n                'model_class': PadimLightningModule\n            }\n            print(\"‚úÖ Anomalib legacy API detected\")\n            \n        except ImportError:\n            print(\"‚ö†Ô∏è No anomalib API detected - will use manual implementation\")\n            ANOMALIB_VERSION = \"manual\"\n\n# Step 3: Manual PaDiM implementation as ultimate fallback\nclass ManualPaDiM:\n    \"\"\"Manual PaDiM implementation when anomalib fails\"\"\"\n    \n    def __init__(self, backbone='resnet18', layers=['layer1', 'layer2', 'layer3']):\n        self.backbone_name = backbone\n        self.layer_names = layers\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"üß† Manual PaDiM initialized with {backbone} on {self.device}\")\n        \n        # Load pretrained backbone\n        if backbone == 'resnet18':\n            import torchvision.models as models\n            self.backbone = models.resnet18(pretrained=True)\n            self.backbone.eval()\n            self.backbone.to(self.device)\n        \n        self.feature_extractor = {}\n        self._register_hooks()\n        \n    def _register_hooks(self):\n        \"\"\"Register hooks for specified layers\"\"\"\n        def hook_fn(name):\n            def hook(module, input, output):\n                self.feature_extractor[name] = output\n            return hook\n        \n        # Register hooks for specified layers\n        for name, module in self.backbone.named_modules():\n            if name in self.layer_names:\n                module.register_forward_hook(hook_fn(name))\n    \n    def extract_features(self, images):\n        \"\"\"Extract features from images\"\"\"\n        self.feature_extractor.clear()\n        \n        with torch.no_grad():\n            _ = self.backbone(images)\n        \n        # Concatenate features from all layers\n        feature_maps = []\n        for layer_name in self.layer_names:\n            if layer_name in self.feature_extractor:\n                feat = self.feature_extractor[layer_name]\n                # Adaptive pool to standard size\n                feat = torch.nn.functional.adaptive_avg_pool2d(feat, (28, 28))\n                feature_maps.append(feat)\n        \n        if feature_maps:\n            return torch.cat(feature_maps, dim=1)\n        else:\n            print(\"‚ö†Ô∏è No features extracted\")\n            return None\n    \n    def fit(self, train_loader):\n        \"\"\"Fit the model on training data\"\"\"\n        print(\"üîÑ Training manual PaDiM...\")\n        \n        all_features = []\n        \n        for batch_idx, (images, _) in enumerate(train_loader):\n            if batch_idx % 10 == 0:\n                print(f\"Processing batch {batch_idx}...\")\n            \n            images = images.to(self.device)\n            features = self.extract_features(images)\n            \n            if features is not None:\n                # Reshape to (batch_size * height * width, features)\n                b, c, h, w = features.shape\n                features = features.permute(0, 2, 3, 1).reshape(-1, c)\n                all_features.append(features.cpu().numpy())\n        \n        if all_features:\n            all_features = np.vstack(all_features)\n            \n            # Calculate mean and covariance for each spatial location\n            self.mean = np.mean(all_features, axis=0)\n            self.cov = np.cov(all_features, rowvar=False)\n            \n            # Add small epsilon to diagonal for numerical stability\n            self.cov += np.eye(self.cov.shape[0]) * 1e-6\n            \n            print(f\"‚úÖ Training completed. Feature shape: {all_features.shape}\")\n            return True\n        else:\n            print(\"‚ùå No features extracted during training\")\n            return False\n    \n    def predict(self, test_loader):\n        \"\"\"Predict anomalies on test data\"\"\"\n        print(\"üîç Predicting with manual PaDiM...\")\n        \n        predictions = []\n        true_labels = []\n        \n        for batch_idx, (images, labels) in enumerate(test_loader):\n            images = images.to(self.device)\n            features = self.extract_features(images)\n            \n            true_labels.extend(labels.numpy())\n            \n            if features is not None:\n                b, c, h, w = features.shape\n                features = features.permute(0, 2, 3, 1).reshape(-1, c).cpu().numpy()\n                \n                # Calculate Mahalanobis distance\n                diff = features - self.mean\n                try:\n                    inv_cov = np.linalg.pinv(self.cov)\n                    distances = np.sum(diff @ inv_cov * diff, axis=1)\n                    distances = distances.reshape(b, h, w)\n                    \n                    # Max pooling to get image-level score\n                    image_scores = np.max(distances, axis=(1, 2))\n                    predictions.extend(image_scores)\n                    \n                except Exception as e:\n                    print(f\"‚ö†Ô∏è Error in distance calculation: {e}\")\n                    predictions.extend([0.5] * b)\n            else:\n                predictions.extend([0.5] * len(labels))\n        \n        return np.array(predictions), np.array(true_labels)\n\n# Step 4: Enhanced dataset exploration\ndef explore_dataset_structure():\n    \"\"\"Thoroughly explore the MVTec dataset structure\"\"\"\n    print(\"\\nüìÇ Downloading and exploring MVTec dataset...\")\n    \n    try:\n        # Download dataset\n        dataset_path = kagglehub.dataset_download(\"shashankroy568/mvtec-anomaly-detection\")\n        print(f\"‚úÖ Dataset downloaded to: {dataset_path}\")\n        \n        root_path = Path(dataset_path)\n        \n        # Look for MVTec categories\n        mvtec_categories = [\n            'bottle', 'cable', 'capsule', 'carpet', 'grid',\n            'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n            'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n        ]\n        \n        print(f\"\\nüîç Searching for MVTec categories...\")\n        \n        # Recursive search for categories\n        found_categories = {}\n        \n        for root, dirs, files in os.walk(root_path):\n            for dir_name in dirs:\n                if dir_name in mvtec_categories:\n                    category_path = Path(root) / dir_name\n                    found_categories[dir_name] = category_path\n                    print(f\"  ‚úÖ Found {dir_name} at: {category_path}\")\n        \n        if found_categories:\n            print(f\"\\nüéØ Found {len(found_categories)} MVTec categories!\")\n            return root_path, found_categories\n        \n        else:\n            print(\"‚ùå No MVTec categories found in expected locations\")\n            return root_path, {}\n    \n    except Exception as e:\n        print(f\"‚ùå Dataset exploration error: {e}\")\n        return None, {}\n\n# Step 5: FIXED manual dataset class with correct label logic\nclass MVTecManualDataset(Dataset):\n    \"\"\"Manual MVTec dataset when anomalib fails - FIXED LABEL LOGIC\"\"\"\n    \n    def __init__(self, root_path, category, split='train', transform=None):\n        self.root_path = Path(root_path)\n        self.category = category\n        self.split = split\n        self.transform = transform or transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        self.samples = self._load_samples()\n        print(f\"üìä {category}: Loaded {len(self.samples)} {split} samples\")\n    \n    def _load_samples(self):\n        \"\"\"Load all samples for the dataset with CORRECT MVTec labeling\"\"\"\n        samples = []\n        \n        # Find category path\n        possible_paths = [\n            self.root_path / self.category,\n            self.root_path / \"mvtec_anomaly_detection\" / self.category,\n            self.root_path / \"MVTec\" / self.category,\n            self.root_path / \"mvtec\" / self.category\n        ]\n        \n        category_path = None\n        for path in possible_paths:\n            if path.exists():\n                category_path = path\n                break\n        \n        if not category_path:\n            print(f\"‚ùå Category path not found for {self.category}\")\n            return samples\n        \n        if self.split == 'train':\n            # Training: Only normal samples from train/good\n            good_path = category_path / 'train' / 'good'\n            if good_path.exists():\n                for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                    for img_path in good_path.rglob(ext):\n                        samples.append((str(img_path), 0))  # Label 0 = Normal\n        else:  # test split\n            # Test: Both normal and anomaly samples\n            test_path = category_path / 'test'\n            if test_path.exists():\n                # Load normal test samples from test/good\n                good_test_path = test_path / 'good'\n                if good_test_path.exists():\n                    for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                        for img_path in good_test_path.rglob(ext):\n                            samples.append((str(img_path), 0))  # Label 0 = Normal\n                \n                # Load anomaly samples from test/defect_type folders\n                for defect_dir in test_path.iterdir():\n                    if defect_dir.is_dir() and defect_dir.name != 'good':\n                        for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                            for img_path in defect_dir.rglob(ext):\n                                samples.append((str(img_path), 1))  # Label 1 = Anomaly\n        \n        # Count samples by label\n        normal_count = len([s for s in samples if s[1] == 0])\n        anomaly_count = len([s for s in samples if s[1] == 1])\n        \n        print(f\"   ‚úÖ {self.category} {self.split}: {normal_count} normal, {anomaly_count} anomaly\")\n        \n        return samples\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error loading {img_path}: {e}\")\n            # Return dummy data\n            dummy_image = torch.zeros((3, 224, 224))\n            return dummy_image, label\n\n# Step 6: Single category training function\ndef train_single_category(root_path, category, results_dict):\n    \"\"\"Train PaDiM on a single category\"\"\"\n    \n    print(f\"\\n\" + \"=\"*50)\n    print(f\"üöÄ TRAINING CATEGORY: {category.upper()}\")\n    print(f\"=\"*50)\n    \n    start_time = time.time()\n    \n    try:\n        # Create datasets\n        train_dataset = MVTecManualDataset(root_path, category, 'train')\n        test_dataset = MVTecManualDataset(root_path, category, 'test')\n        \n        # Safety checks\n        if len(train_dataset) == 0:\n            print(f\"‚ùå No training samples found for {category}\")\n            results_dict[category] = {'status': 'failed', 'reason': 'no_train_data'}\n            return\n            \n        if len(test_dataset) == 0:\n            print(f\"‚ùå No test samples found for {category}\")\n            results_dict[category] = {'status': 'failed', 'reason': 'no_test_data'}\n            return\n        \n        # Check test labels\n        test_labels = [test_dataset.samples[i][1] for i in range(len(test_dataset))]\n        unique_labels = set(test_labels)\n        \n        if len(unique_labels) < 2:\n            print(f\"‚ö†Ô∏è Warning: {category} test set only has {unique_labels} labels\")\n            results_dict[category] = {'status': 'failed', 'reason': 'insufficient_labels'}\n            return\n        \n        # Create data loaders\n        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n        \n        print(f\"‚úÖ {category}: Dataset ready - {len(train_dataset)} train, {len(test_dataset)} test\")\n        \n        # Train model\n        print(f\"üß† Training PaDiM for {category}...\")\n        model = ManualPaDiM()\n        \n        training_success = model.fit(train_loader)\n        \n        if not training_success:\n            results_dict[category] = {'status': 'failed', 'reason': 'training_failed'}\n            return\n        \n        # Test model\n        predictions, true_labels = model.predict(test_loader)\n        \n        # Calculate metrics\n        if len(predictions) == len(true_labels) and len(predictions) > 0:\n            unique_test_labels = set(true_labels)\n            \n            if len(unique_test_labels) >= 2:\n                auc_score = roc_auc_score(true_labels, predictions)\n                \n                # Calculate additional metrics\n                normal_indices = true_labels == 0\n                anomaly_indices = true_labels == 1\n                \n                normal_scores = predictions[normal_indices] if normal_indices.any() else np.array([])\n                anomaly_scores = predictions[anomaly_indices] if anomaly_indices.any() else np.array([])\n                \n                training_time = time.time() - start_time\n                \n                # Store results\n                results_dict[category] = {\n                    'status': 'success',\n                    'auc_score': auc_score,\n                    'train_samples': len(train_dataset),\n                    'test_samples': len(test_dataset),\n                    'normal_test_samples': len(normal_scores),\n                    'anomaly_test_samples': len(anomaly_scores),\n                    'normal_mean_score': float(normal_scores.mean()) if len(normal_scores) > 0 else 0,\n                    'anomaly_mean_score': float(anomaly_scores.mean()) if len(anomaly_scores) > 0 else 0,\n                    'training_time': training_time\n                }\n                \n                print(f\"‚úÖ {category}: AUC Score = {auc_score:.4f}\")\n                print(f\"üìä {category}: Normal scores = {normal_scores.mean():.2f}, Anomaly scores = {anomaly_scores.mean():.2f}\")\n                print(f\"‚è±Ô∏è  {category}: Training time = {training_time:.1f}s\")\n                \n            else:\n                results_dict[category] = {'status': 'failed', 'reason': 'insufficient_test_labels'}\n        else:\n            results_dict[category] = {'status': 'failed', 'reason': 'prediction_mismatch'}\n            \n    except Exception as e:\n        print(f\"‚ùå {category}: Training failed - {e}\")\n        results_dict[category] = {'status': 'failed', 'reason': str(e)}\n\n# Step 7: Multi-category training pipeline\ndef run_multi_category_pipeline():\n    \"\"\"Train on all target categories\"\"\"\n    \n    print(\"üöÄ Starting Multi-Category Anomaly Detection Pipeline\")\n    print(\"=\" * 70)\n    \n    # Explore dataset\n    root_path, categories = explore_dataset_structure()\n    \n    if not root_path or not categories:\n        print(\"‚ùå Cannot proceed without dataset\")\n        return\n    \n    # Target categories for warehouse research\n    target_categories = ['bottle', 'metal_nut', 'capsule', 'cable']\n    available_targets = [cat for cat in target_categories if cat in categories]\n    \n    if not available_targets:\n        print(\"‚ùå No target categories found in dataset\")\n        return\n    \n    print(f\"\\nüéØ Will train on {len(available_targets)} categories: {available_targets}\")\n    \n    # Train each category\n    results = {}\n    total_start_time = time.time()\n    \n    for i, category in enumerate(available_targets, 1):\n        print(f\"\\nüîÑ Progress: {i}/{len(available_targets)} categories\")\n        train_single_category(root_path, category, results)\n    \n    total_time = time.time() - total_start_time\n    \n    # Generate comprehensive results summary\n    print(f\"\\n\" + \"=\"*70)\n    print(\"üìã MULTI-CATEGORY TRAINING RESULTS\")\n    print(\"=\"*70)\n    \n    successful_trainings = [cat for cat, res in results.items() if res.get('status') == 'success']\n    failed_trainings = [cat for cat, res in results.items() if res.get('status') == 'failed']\n    \n    print(f\"‚úÖ Successful: {len(successful_trainings)}/{len(available_targets)} categories\")\n    print(f\"‚ùå Failed: {len(failed_trainings)}/{len(available_targets)} categories\")\n    print(f\"‚è±Ô∏è  Total time: {total_time:.1f}s\")\n    \n    # Detailed results table\n    if successful_trainings:\n        print(f\"\\nüìä DETAILED RESULTS:\")\n        print(\"-\" * 90)\n        print(f\"{'Category':<12} {'AUC Score':<10} {'Train':<7} {'Test':<6} {'Normal':<8} {'Anomaly':<8} {'Time':<6}\")\n        print(\"-\" * 90)\n        \n        for category in successful_trainings:\n            res = results[category]\n            print(f\"{category:<12} {res['auc_score']:<10.4f} {res['train_samples']:<7} {res['test_samples']:<6} \"\n                  f\"{res['normal_test_samples']:<8} {res['anomaly_test_samples']:<8} {res['training_time']:<6.1f}s\")\n        \n        # Calculate average AUC\n        avg_auc = np.mean([results[cat]['auc_score'] for cat in successful_trainings])\n        print(\"-\" * 90)\n        print(f\"{'AVERAGE':<12} {avg_auc:<10.4f}\")\n        print(\"-\" * 90)\n    \n    # Failed categories details\n    if failed_trainings:\n        print(f\"\\n‚ùå FAILED CATEGORIES:\")\n        for category in failed_trainings:\n            reason = results[category].get('reason', 'unknown')\n            print(f\"   {category}: {reason}\")\n    \n    # Research summary\n    print(f\"\\nüéì RESEARCH SUMMARY:\")\n    print(f\"   Dataset: MVTec Anomaly Detection\")\n    print(f\"   Model: PaDiM (Manual Implementation)\")\n    print(f\"   Categories: {len(successful_trainings)} warehouse-relevant products\")\n    print(f\"   Performance: {avg_auc:.4f} average AUC score\" if successful_trainings else \"   Performance: No successful trainings\")\n    print(f\"   Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n    \n    # Export results to CSV for research paper\n    if successful_trainings:\n        results_df = pd.DataFrame([\n            {\n                'category': category,\n                'auc_score': results[category]['auc_score'],\n                'train_samples': results[category]['train_samples'],\n                'test_samples': results[category]['test_samples'],\n                'normal_test_samples': results[category]['normal_test_samples'],\n                'anomaly_test_samples': results[category]['anomaly_test_samples'],\n                'normal_mean_score': results[category]['normal_mean_score'],\n                'anomaly_mean_score': results[category]['anomaly_mean_score'],\n                'training_time': results[category]['training_time']\n            }\n            for category in successful_trainings\n        ])\n        \n        results_df.to_csv('mvtec_padim_results.csv', index=False)\n        print(f\"\\nüíæ Results exported to: mvtec_padim_results.csv\")\n    \n    print(f\"\\nüéâ Multi-category training pipeline completed!\")\n    return results\n\n# Execute the multi-category pipeline\nif __name__ == \"__main__\":\n    results = run_multi_category_pipeline()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T07:45:47.281956Z","iopub.execute_input":"2025-09-13T07:45:47.282268Z","iopub.status.idle":"2025-09-13T07:46:58.749747Z","shell.execute_reply.started":"2025-09-13T07:45:47.282244Z","shell.execute_reply":"2025-09-13T07:46:58.748961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MVTec Anomaly Detection - Multi-Category Training with PaDiM\n# Designed for Kaggle GPU P100 environment\nimport os\nimport sys\nimport warnings\nimport subprocess\nwarnings.filterwarnings('ignore')\n\nprint(\"üîß Starting robust environment setup...\")\n\ndef install_package(package_name, import_name=None, extra_args=\"\"):\n    \"\"\"Install package with proper error handling\"\"\"\n    try:\n        # Try importing first\n        if import_name:\n            __import__(import_name)\n            print(f\"‚úÖ {package_name} already available\")\n            return True\n        \n        print(f\"Installing {package_name}...\")\n        cmd = f\"pip install {package_name} {extra_args}\"\n        result = subprocess.run(cmd.split(), capture_output=True, text=True)\n        \n        if result.returncode == 0:\n            print(f\"‚úÖ {package_name} installed successfully\")\n            return True\n        else:\n            print(f\"‚ö†Ô∏è Warning installing {package_name}: {result.stderr}\")\n            return False\n            \n    except Exception as e:\n        print(f\"‚ùå Error with {package_name}: {e}\")\n        return False\n\n# Step 1: Install all dependencies step by step\nprint(\"üì¶ Installing dependencies...\")\n# Core dependencies first\ninstall_package(\"python-dotenv\", \"dotenv\", \"--quiet\")\ninstall_package(\"opencv-python\", \"cv2\", \"--quiet\")\ninstall_package(\"Pillow\", \"PIL\", \"--quiet --upgrade\")\n\n# Try different anomalib installation strategies\nprint(\"\\nüîß Installing anomalib with multiple strategies...\")\nstrategies = [\n    (\"anomalib\", \"--quiet --no-deps --upgrade\"),\n    (\"anomalib\", \"--quiet --force-reinstall\"),\n    (\"anomalib==1.0.1\", \"--quiet\"),\n    (\"git+https://github.com/openvinotoolkit/anomalib.git\", \"--quiet\")\n]\n\nanomalib_installed = False\nfor package, args in strategies:\n    print(f\"Trying: pip install {package} {args}\")\n    if install_package(package, None, args):\n        # Test import after each installation\n        try:\n            import anomalib\n            print(f\"‚úÖ Anomalib successfully imported!\")\n            anomalib_installed = True\n            break\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Installation succeeded but import failed: {e}\")\n            continue\n\nif not anomalib_installed:\n    print(\"‚ö†Ô∏è Anomalib installation issues detected. Using manual approach...\")\n\n# Step 2: Import required libraries with comprehensive fallbacks\nprint(\"\\nüìö Importing libraries...\")\n# Standard imports\ntry:\n    import kagglehub\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    from pathlib import Path\n    import torch\n    from PIL import Image\n    import cv2\n    from glob import glob\n    import json\n    from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, f1_score, confusion_matrix\n    from sklearn.preprocessing import MinMaxScaler\n    import torchvision.transforms as transforms\n    from torch.utils.data import Dataset, DataLoader\n    import time\n    \n    print(\"‚úÖ Standard libraries imported\")\nexcept ImportError as e:\n    print(f\"‚ùå Standard import error: {e}\")\n    sys.exit(1)\n\n# Anomalib imports with multiple fallback options\nANOMALIB_VERSION = None\nanomalib_components = {}\nprint(\"üîç Detecting anomalib configuration...\")\n\n# Strategy 1: Try latest anomalib API\ntry:\n    from anomalib import TaskType\n    from anomalib.data.image.mvtec import MVTecDataModule\n    from anomalib.models.image.padim import Padim, PadimLightningModule\n    from anomalib.engine import Engine\n    \n    ANOMALIB_VERSION = \"v1.0+\"\n    anomalib_components = {\n        'datamodule_class': MVTecDataModule,\n        'model_class': Padim,\n        'engine_class': Engine\n    }\n    print(\"‚úÖ Anomalib v1.0+ API detected\")\n    \nexcept ImportError:\n    # Strategy 2: Try older anomalib API\n    try:\n        from anomalib.data import MVTec\n        from anomalib.models.padim import Padim, PadimLightningModule\n        from anomalib.utils.callbacks import get_callbacks\n        \n        ANOMALIB_VERSION = \"v0.7+\"\n        anomalib_components = {\n            'datamodule_class': MVTec,\n            'model_class': Padim,\n            'callbacks_fn': get_callbacks\n        }\n        print(\"‚úÖ Anomalib v0.7+ API detected\")\n        \n    except ImportError:\n        # Strategy 3: Try even older API\n        try:\n            from anomalib.data.mvtec import MVTecDataset\n            from anomalib.models.padim.lightning_model import PadimLightningModule\n            \n            ANOMALIB_VERSION = \"legacy\"\n            anomalib_components = {\n                'dataset_class': MVTecDataset,\n                'model_class': PadimLightningModule\n            }\n            print(\"‚úÖ Anomalib legacy API detected\")\n            \n        except ImportError:\n            print(\"‚ö†Ô∏è No anomalib API detected - will use manual implementation\")\n            ANOMALIB_VERSION = \"manual\"\n\n# Helper functions for enhanced metrics calculation\ndef calculate_optimal_threshold(y_true, y_scores):\n    \"\"\"Calculate optimal threshold using Youden's J statistic\"\"\"\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n    j_scores = tpr - fpr  # Youden's J statistic\n    best_threshold_idx = np.argmax(j_scores)\n    best_threshold = thresholds[best_threshold_idx]\n    return best_threshold\n\ndef calculate_comprehensive_metrics(y_true, y_scores, threshold=None):\n    \"\"\"Calculate comprehensive metrics including precision, recall, F1\"\"\"\n    if threshold is None:\n        threshold = calculate_optimal_threshold(y_true, y_scores)\n    \n    # Convert scores to binary predictions\n    y_pred = (y_scores >= threshold).astype(int)\n    \n    # Calculate metrics\n    precision = precision_score(y_true, y_pred, zero_division=0)\n    recall = recall_score(y_true, y_pred, zero_division=0)\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    \n    # Additional metrics from confusion matrix\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n    \n    return {\n        'threshold': threshold,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'specificity': specificity,\n        'accuracy': accuracy,\n        'true_positives': int(tp),\n        'true_negatives': int(tn),\n        'false_positives': int(fp),\n        'false_negatives': int(fn)\n    }\n\n# Step 3: Manual PaDiM implementation as ultimate fallback\nclass ManualPaDiM:\n    \"\"\"Manual PaDiM implementation when anomalib fails\"\"\"\n    \n    def __init__(self, backbone='resnet18', layers=['layer1', 'layer2', 'layer3']):\n        self.backbone_name = backbone\n        self.layer_names = layers\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"üß† Manual PaDiM initialized with {backbone} on {self.device}\")\n        \n        # Load pretrained backbone\n        if backbone == 'resnet18':\n            import torchvision.models as models\n            self.backbone = models.resnet18(pretrained=True)\n            self.backbone.eval()\n            self.backbone.to(self.device)\n        \n        self.feature_extractor = {}\n        self._register_hooks()\n        \n    def _register_hooks(self):\n        \"\"\"Register hooks for specified layers\"\"\"\n        def hook_fn(name):\n            def hook(module, input, output):\n                self.feature_extractor[name] = output\n            return hook\n        \n        # Register hooks for specified layers\n        for name, module in self.backbone.named_modules():\n            if name in self.layer_names:\n                module.register_forward_hook(hook_fn(name))\n    \n    def extract_features(self, images):\n        \"\"\"Extract features from images\"\"\"\n        self.feature_extractor.clear()\n        \n        with torch.no_grad():\n            _ = self.backbone(images)\n        \n        # Concatenate features from all layers\n        feature_maps = []\n        for layer_name in self.layer_names:\n            if layer_name in self.feature_extractor:\n                feat = self.feature_extractor[layer_name]\n                # Adaptive pool to standard size\n                feat = torch.nn.functional.adaptive_avg_pool2d(feat, (28, 28))\n                feature_maps.append(feat)\n        \n        if feature_maps:\n            return torch.cat(feature_maps, dim=1)\n        else:\n            print(\"‚ö†Ô∏è No features extracted\")\n            return None\n    \n    def fit(self, train_loader):\n        \"\"\"Fit the model on training data\"\"\"\n        print(\"üîÑ Training manual PaDiM...\")\n        \n        all_features = []\n        \n        for batch_idx, (images, _) in enumerate(train_loader):\n            if batch_idx % 10 == 0:\n                print(f\"Processing batch {batch_idx}...\")\n            \n            images = images.to(self.device)\n            features = self.extract_features(images)\n            \n            if features is not None:\n                # Reshape to (batch_size * height * width, features)\n                b, c, h, w = features.shape\n                features = features.permute(0, 2, 3, 1).reshape(-1, c)\n                all_features.append(features.cpu().numpy())\n        \n        if all_features:\n            all_features = np.vstack(all_features)\n            \n            # Calculate mean and covariance for each spatial location\n            self.mean = np.mean(all_features, axis=0)\n            self.cov = np.cov(all_features, rowvar=False)\n            \n            # Add small epsilon to diagonal for numerical stability\n            self.cov += np.eye(self.cov.shape[0]) * 1e-6\n            \n            print(f\"‚úÖ Training completed. Feature shape: {all_features.shape}\")\n            return True\n        else:\n            print(\"‚ùå No features extracted during training\")\n            return False\n    \n    def predict(self, test_loader):\n        \"\"\"Predict anomalies on test data\"\"\"\n        print(\"üîç Predicting with manual PaDiM...\")\n        \n        predictions = []\n        true_labels = []\n        \n        for batch_idx, (images, labels) in enumerate(test_loader):\n            images = images.to(self.device)\n            features = self.extract_features(images)\n            \n            true_labels.extend(labels.numpy())\n            \n            if features is not None:\n                b, c, h, w = features.shape\n                features = features.permute(0, 2, 3, 1).reshape(-1, c).cpu().numpy()\n                \n                # Calculate Mahalanobis distance\n                diff = features - self.mean\n                try:\n                    inv_cov = np.linalg.pinv(self.cov)\n                    distances = np.sum(diff @ inv_cov * diff, axis=1)\n                    distances = distances.reshape(b, h, w)\n                    \n                    # Max pooling to get image-level score\n                    image_scores = np.max(distances, axis=(1, 2))\n                    predictions.extend(image_scores)\n                    \n                except Exception as e:\n                    print(f\"‚ö†Ô∏è Error in distance calculation: {e}\")\n                    predictions.extend([0.5] * b)\n            else:\n                predictions.extend([0.5] * len(labels))\n        \n        return np.array(predictions), np.array(true_labels)\n\n# Step 4: Enhanced dataset exploration\ndef explore_dataset_structure():\n    \"\"\"Thoroughly explore the MVTec dataset structure\"\"\"\n    print(\"\\nüìÇ Downloading and exploring MVTec dataset...\")\n    \n    try:\n        # Download dataset\n        dataset_path = kagglehub.dataset_download(\"shashankroy568/mvtec-anomaly-detection\")\n        print(f\"‚úÖ Dataset downloaded to: {dataset_path}\")\n        \n        root_path = Path(dataset_path)\n        \n        # Look for MVTec categories\n        mvtec_categories = [\n            'bottle', 'cable', 'capsule', 'carpet', 'grid',\n            'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n            'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n        ]\n        \n        print(f\"\\nüîç Searching for MVTec categories...\")\n        \n        # Recursive search for categories\n        found_categories = {}\n        \n        for root, dirs, files in os.walk(root_path):\n            for dir_name in dirs:\n                if dir_name in mvtec_categories:\n                    category_path = Path(root) / dir_name\n                    found_categories[dir_name] = category_path\n                    print(f\"  ‚úÖ Found {dir_name} at: {category_path}\")\n        \n        if found_categories:\n            print(f\"\\nüéØ Found {len(found_categories)} MVTec categories!\")\n            return root_path, found_categories\n        \n        else:\n            print(\"‚ùå No MVTec categories found in expected locations\")\n            return root_path, {}\n    \n    except Exception as e:\n        print(f\"‚ùå Dataset exploration error: {e}\")\n        return None, {}\n\n# Step 5: FIXED manual dataset class with correct label logic\nclass MVTecManualDataset(Dataset):\n    \"\"\"Manual MVTec dataset when anomalib fails - FIXED LABEL LOGIC\"\"\"\n    \n    def __init__(self, root_path, category, split='train', transform=None):\n        self.root_path = Path(root_path)\n        self.category = category\n        self.split = split\n        self.transform = transform or transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        self.samples = self._load_samples()\n        print(f\"üìä {category}: Loaded {len(self.samples)} {split} samples\")\n    \n    def _load_samples(self):\n        \"\"\"Load all samples for the dataset with CORRECT MVTec labeling\"\"\"\n        samples = []\n        \n        # Find category path\n        possible_paths = [\n            self.root_path / self.category,\n            self.root_path / \"mvtec_anomaly_detection\" / self.category,\n            self.root_path / \"MVTec\" / self.category,\n            self.root_path / \"mvtec\" / self.category\n        ]\n        \n        category_path = None\n        for path in possible_paths:\n            if path.exists():\n                category_path = path\n                break\n        \n        if not category_path:\n            print(f\"‚ùå Category path not found for {self.category}\")\n            return samples\n        \n        if self.split == 'train':\n            # Training: Only normal samples from train/good\n            good_path = category_path / 'train' / 'good'\n            if good_path.exists():\n                for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                    for img_path in good_path.rglob(ext):\n                        samples.append((str(img_path), 0))  # Label 0 = Normal\n        else:  # test split\n            # Test: Both normal and anomaly samples\n            test_path = category_path / 'test'\n            if test_path.exists():\n                # Load normal test samples from test/good\n                good_test_path = test_path / 'good'\n                if good_test_path.exists():\n                    for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                        for img_path in good_test_path.rglob(ext):\n                            samples.append((str(img_path), 0))  # Label 0 = Normal\n                \n                # Load anomaly samples from test/defect_type folders\n                for defect_dir in test_path.iterdir():\n                    if defect_dir.is_dir() and defect_dir.name != 'good':\n                        for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp']:\n                            for img_path in defect_dir.rglob(ext):\n                                samples.append((str(img_path), 1))  # Label 1 = Anomaly\n        \n        # Count samples by label\n        normal_count = len([s for s in samples if s[1] == 0])\n        anomaly_count = len([s for s in samples if s[1] == 1])\n        \n        print(f\"   ‚úÖ {self.category} {self.split}: {normal_count} normal, {anomaly_count} anomaly\")\n        \n        return samples\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error loading {img_path}: {e}\")\n            # Return dummy data\n            dummy_image = torch.zeros((3, 224, 224))\n            return dummy_image, label\n\n# Step 6: Enhanced single category training function with comprehensive metrics\ndef train_single_category(root_path, category, results_dict):\n    \"\"\"Train PaDiM on a single category with comprehensive metrics\"\"\"\n    \n    print(f\"\\n\" + \"=\"*50)\n    print(f\"üöÄ TRAINING PADIM: {category.upper()}\")\n    print(f\"=\"*50)\n    \n    start_time = time.time()\n    \n    try:\n        # Create datasets\n        train_dataset = MVTecManualDataset(root_path, category, 'train')\n        test_dataset = MVTecManualDataset(root_path, category, 'test')\n        \n        # Safety checks\n        if len(train_dataset) == 0:\n            print(f\"‚ùå No training samples found for {category}\")\n            results_dict[category] = {'status': 'failed', 'reason': 'no_train_data'}\n            return\n            \n        if len(test_dataset) == 0:\n            print(f\"‚ùå No test samples found for {category}\")\n            results_dict[category] = {'status': 'failed', 'reason': 'no_test_data'}\n            return\n        \n        # Check test labels\n        test_labels = [test_dataset.samples[i][1] for i in range(len(test_dataset))]\n        unique_labels = set(test_labels)\n        \n        if len(unique_labels) < 2:\n            print(f\"‚ö†Ô∏è Warning: {category} test set only has {unique_labels} labels\")\n            results_dict[category] = {'status': 'failed', 'reason': 'insufficient_labels'}\n            return\n        \n        # Create data loaders\n        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n        test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n        \n        print(f\"‚úÖ {category}: Dataset ready - {len(train_dataset)} train, {len(test_dataset)} test\")\n        \n        # Train model\n        print(f\"üß† Training PaDiM for {category}...\")\n        model = ManualPaDiM()\n        \n        training_success = model.fit(train_loader)\n        \n        if not training_success:\n            results_dict[category] = {'status': 'failed', 'reason': 'training_failed'}\n            return\n        \n        # Test model\n        predictions, true_labels = model.predict(test_loader)\n        \n        # Calculate comprehensive metrics\n        if len(predictions) == len(true_labels) and len(predictions) > 0:\n            unique_test_labels = set(true_labels)\n            \n            if len(unique_test_labels) >= 2:\n                auc_score = roc_auc_score(true_labels, predictions)\n                \n                # Calculate comprehensive metrics\n                comprehensive_metrics = calculate_comprehensive_metrics(true_labels, predictions)\n                \n                # Calculate additional statistics\n                normal_indices = true_labels == 0\n                anomaly_indices = true_labels == 1\n                \n                normal_scores = predictions[normal_indices] if normal_indices.any() else np.array([])\n                anomaly_scores = predictions[anomaly_indices] if anomaly_indices.any() else np.array([])\n                \n                training_time = time.time() - start_time\n                \n                # Store comprehensive results\n                results_dict[category] = {\n                    'status': 'success',\n                    'auc_score': auc_score,\n                    'precision': comprehensive_metrics['precision'],\n                    'recall': comprehensive_metrics['recall'],\n                    'f1_score': comprehensive_metrics['f1_score'],\n                    'specificity': comprehensive_metrics['specificity'],\n                    'accuracy': comprehensive_metrics['accuracy'],\n                    'threshold': comprehensive_metrics['threshold'],\n                    'true_positives': comprehensive_metrics['true_positives'],\n                    'true_negatives': comprehensive_metrics['true_negatives'],\n                    'false_positives': comprehensive_metrics['false_positives'],\n                    'false_negatives': comprehensive_metrics['false_negatives'],\n                    'train_samples': len(train_dataset),\n                    'test_samples': len(test_dataset),\n                    'normal_test_samples': len(normal_scores),\n                    'anomaly_test_samples': len(anomaly_scores),\n                    'normal_mean_score': float(normal_scores.mean()) if len(normal_scores) > 0 else 0,\n                    'anomaly_mean_score': float(anomaly_scores.mean()) if len(anomaly_scores) > 0 else 0,\n                    'training_time': training_time,\n                    'model_type': 'manual_padim'\n                }\n                \n                print(f\"‚úÖ {category}: AUC Score = {auc_score:.4f}\")\n                print(f\"üìä {category}: Precision = {comprehensive_metrics['precision']:.4f}, Recall = {comprehensive_metrics['recall']:.4f}, F1 = {comprehensive_metrics['f1_score']:.4f}\")\n                print(f\"üìä {category}: Normal scores = {normal_scores.mean():.2f}, Anomaly scores = {anomaly_scores.mean():.2f}\")\n                print(f\"‚è±Ô∏è  {category}: Training time = {training_time:.1f}s\")\n                \n            else:\n                results_dict[category] = {'status': 'failed', 'reason': 'insufficient_test_labels'}\n        else:\n            results_dict[category] = {'status': 'failed', 'reason': 'prediction_mismatch'}\n            \n    except Exception as e:\n        print(f\"‚ùå {category}: Training failed - {e}\")\n        import traceback\n        traceback.print_exc()\n        results_dict[category] = {'status': 'failed', 'reason': str(e)}\n\n# Step 7: Multi-category training pipeline with 8 categories\ndef run_multi_category_pipeline():\n    \"\"\"Train on all 8 target categories\"\"\"\n    \n    print(\"üöÄ Starting Multi-Category PaDiM Pipeline\")\n    print(\"=\" * 70)\n    \n    # Explore dataset\n    root_path, categories = explore_dataset_structure()\n    \n    if not root_path or not categories:\n        print(\"‚ùå Cannot proceed without dataset\")\n        return\n    \n    # ALL 8 TARGET CATEGORIES - Updated as requested\n    target_categories = ['bottle', 'metal_nut', 'capsule', 'cable', 'screw', 'pill', 'transistor', 'hazelnut']\n    available_targets = [cat for cat in target_categories if cat in categories]\n    \n    if not available_targets:\n        print(\"‚ùå No target categories found in dataset\")\n        return\n    \n    print(f\"\\nüéØ Will train PaDiM on {len(available_targets)} categories: {available_targets}\")\n    \n    # Train each category\n    results = {}\n    total_start_time = time.time()\n    \n    for i, category in enumerate(available_targets, 1):\n        print(f\"\\nüîÑ Progress: {i}/{len(available_targets)} categories\")\n        train_single_category(root_path, category, results)\n    \n    total_time = time.time() - total_start_time\n    \n    # Generate comprehensive results summary\n    print(f\"\\n\" + \"=\"*70)\n    print(\"üìã MULTI-CATEGORY PADIM RESULTS WITH PRECISION & RECALL\")\n    print(\"=\"*70)\n    \n    successful_trainings = [cat for cat, res in results.items() if res.get('status') == 'success']\n    failed_trainings = [cat for cat, res in results.items() if res.get('status') == 'failed']\n    \n    print(f\"‚úÖ Successful: {len(successful_trainings)}/{len(available_targets)} categories\")\n    print(f\"‚ùå Failed: {len(failed_trainings)}/{len(available_targets)} categories\")\n    print(f\"‚è±Ô∏è  Total time: {total_time:.1f}s\")\n    \n    # Enhanced detailed results table\n    if successful_trainings:\n        print(f\"\\nüìä DETAILED PADIM RESULTS:\")\n        print(\"-\" * 120)\n        print(f\"{'Category':<12} {'AUC':<8} {'Precision':<9} {'Recall':<8} {'F1':<8} {'Acc':<8} {'Train':<6} {'Test':<5} {'Time':<6}\")\n        print(\"-\" * 120)\n        \n        for category in successful_trainings:\n            res = results[category]\n            print(f\"{category:<12} {res['auc_score']:<8.4f} {res['precision']:<9.4f} {res['recall']:<8.4f} \"\n                  f\"{res['f1_score']:<8.4f} {res['accuracy']:<8.4f} {res['train_samples']:<6} {res['test_samples']:<5} \"\n                  f\"{res['training_time']:<6.1f}s\")\n        \n        # Calculate averages\n        avg_auc = np.mean([results[cat]['auc_score'] for cat in successful_trainings])\n        avg_precision = np.mean([results[cat]['precision'] for cat in successful_trainings])\n        avg_recall = np.mean([results[cat]['recall'] for cat in successful_trainings])\n        avg_f1 = np.mean([results[cat]['f1_score'] for cat in successful_trainings])\n        avg_accuracy = np.mean([results[cat]['accuracy'] for cat in successful_trainings])\n        \n        print(\"-\" * 120)\n        print(f\"{'AVERAGE':<12} {avg_auc:<8.4f} {avg_precision:<9.4f} {avg_recall:<8.4f} \"\n              f\"{avg_f1:<8.4f} {avg_accuracy:<8.4f}\")\n        print(\"-\" * 120)\n    \n    # Failed categories details\n    if failed_trainings:\n        print(f\"\\n‚ùå FAILED CATEGORIES:\")\n        for category in failed_trainings:\n            reason = results[category].get('reason', 'unknown')\n            print(f\"   {category}: {reason}\")\n    \n    # Research summary\n    print(f\"\\nüéì PADIM RESEARCH SUMMARY:\")\n    print(f\"   Dataset: MVTec Anomaly Detection\")\n    print(f\"   Model: PaDiM (Manual Implementation)\")\n    print(f\"   Categories: {len(successful_trainings)} warehouse-relevant products\")\n    if successful_trainings:\n        print(f\"   Performance:\")\n        print(f\"     - Average AUC: {avg_auc:.4f}\")\n        print(f\"     - Average Precision: {avg_precision:.4f}\")\n        print(f\"     - Average Recall: {avg_recall:.4f}\")\n        print(f\"     - Average F1-Score: {avg_f1:.4f}\")\n        print(f\"     - Average Accuracy: {avg_accuracy:.4f}\")\n    else:\n        print(f\"   Performance: No successful trainings\")\n    print(f\"   Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n    \n    # Export comprehensive results to CSV for research paper\n    if successful_trainings:\n        results_df = pd.DataFrame([\n            {\n                'category': category,\n                'model': 'PaDiM',\n                'auc_score': results[category]['auc_score'],\n                'precision': results[category]['precision'],\n                'recall': results[category]['recall'],\n                'f1_score': results[category]['f1_score'],\n                'specificity': results[category]['specificity'],\n                'accuracy': results[category]['accuracy'],\n                'threshold': results[category]['threshold'],\n                'true_positives': results[category]['true_positives'],\n                'true_negatives': results[category]['true_negatives'],\n                'false_positives': results[category]['false_positives'],\n                'false_negatives': results[category]['false_negatives'],\n                'train_samples': results[category]['train_samples'],\n                'test_samples': results[category]['test_samples'],\n                'normal_test_samples': results[category]['normal_test_samples'],\n                'anomaly_test_samples': results[category]['anomaly_test_samples'],\n                'normal_mean_score': results[category]['normal_mean_score'],\n                'anomaly_mean_score': results[category]['anomaly_mean_score'],\n                'training_time': results[category]['training_time'],\n                'model_type': results[category]['model_type']\n            }\n            for category in successful_trainings\n        ])\n        \n        results_df.to_csv('mvtec_padim_8categories_results.csv', index=False)\n        print(f\"\\nüíæ PaDiM results exported to: mvtec_padim_8categories_results.csv\")\n        \n        # Show confusion matrix summary\n        print(f\"\\nüîç CONFUSION MATRIX SUMMARY:\")\n        print(\"-\" * 80)\n        print(f\"{'Category':<12} {'TP':<5} {'TN':<5} {'FP':<5} {'FN':<5} {'Threshold':<10}\")\n        print(\"-\" * 80)\n        for category in successful_trainings:\n            res = results[category]\n            print(f\"{category:<12} {res['true_positives']:<5} {res['true_negatives']:<5} \"\n                  f\"{res['false_positives']:<5} {res['false_negatives']:<5} {res['threshold']:<10.4f}\")\n        print(\"-\" * 80)\n    \n    print(f\"\\nüéâ Multi-category PaDiM training pipeline completed!\")\n    return results\n\n# Execute the multi-category pipeline with 8 categories\nif __name__ == \"__main__\":\n    results = run_multi_category_pipeline()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T07:48:51.439235Z","iopub.execute_input":"2025-09-13T07:48:51.439825Z","iopub.status.idle":"2025-09-13T07:50:26.722194Z","shell.execute_reply.started":"2025-09-13T07:48:51.439791Z","shell.execute_reply":"2025-09-13T07:50:26.721409Z"}},"outputs":[],"execution_count":null}]}